{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook is for visualizing each step of the CMMN process so that we can identify the intermediate representations of the whole thing before integrating into our setup.\n",
    "\n",
    "For now, I will eschew the class based formulation that the original authors provided and just implement everything iteratively, as Dr. B suggested.\n",
    "\n",
    "Also, this is now a branch of the ICWaves repo so that we can minimize any potential mistakes from separating things into a different package for now."
   ],
   "id": "29e2d03391921d8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here are the main steps for translating cue -> emotion:\n",
    "\n",
    "1. Load in all source and target data. Emotion has 35 subj.s at 256 hz, cue has 12 subj.s at 500 hz. Load the resampled cue. Since this notebook is for visualization, for now do with a handful of subjects and then visualize with the full list.\n",
    "2. Calculate the normed barycenter of the source data (emotion). Viz.\n",
    "3. For each subject, calculate the filter to transform it to this barycenter. Viz.\n",
    "4. Convolve, visualize before and after of cue.\n",
    "\n",
    "Afterwards add subj. to subj. matching. Normally we can then run this through the clf and get a conf matrix, but Dr. B wants to see these first which I think is a good idea."
   ],
   "id": "f46a56c33cf0b83c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter, sosfilt, welch, freqz, sosfreqz"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# uncomment to viz whole thing\n",
    "# emotion_subj_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35] # note subj. 22 is missing\n",
    "# cue_subj_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# comment out to do more than a few. just a handful for testing the notebook\n",
    "emotion_subj_list = ['1', '2', '3', '4']\n",
    "frolich_subj_list = ['1', '2', '3', '4']"
   ],
   "id": "f518fe4589f6b261"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load in the data\n",
    "emotion_data = []\n",
    "for subj in emotion_subj_list:\n",
    "    emotion_data.append(loadmat(f'../data/emotion_256/raw_emotion_data_and_IC_labels/subj-{subj}.mat')['data'])\n",
    "\n",
    "frolich_data = []\n",
    "for subj in frolich_subj_list:\n",
    "    frolich_data.append(loadmat(f'../data/frolich_500/raw_frolich_data/subj-{subj}.mat')['X'])"
   ],
   "id": "30905413d8e084e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# viz functions\n",
    "def psd(data, fs=256, nperseg=256):\n",
    "    \"\"\"\n",
    "    Compute the Power Spectral Density (PSD) of the given data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: list of numpy arrays, each containing EEG data for a subject\n",
    "    - fs: sampling frequency (default: 256 Hz)\n",
    "    - nperseg: length of each segment for Welch's method (default: 256)\n",
    "\n",
    "    Returns:\n",
    "    - f: array of sample frequencies (x-axis)\n",
    "    - Pxx: power spectral density of the data (y-axis)\n",
    "    \"\"\"\n",
    "    f, Pxx = welch(data, fs=fs, nperseg=nperseg)\n",
    "    return f, Pxx\n",
    "\n",
    "# Define a function to plot PSD\n",
    "def plot_psd(data, fs=256, nperseg=256):\n",
    "    \"\"\"\n",
    "    Plot the Power Spectral Density (PSD) of the given data.\n",
    "\n",
    "    Note: right now this is straight averaging, not the barycenter norming I do later.\n",
    "    If I want to do the norming, apply that first and then this will not average for me.\n",
    "\n",
    "    Parameters:\n",
    "    - data: list of numpy arrays, each containing EEG data for a subject\n",
    "    - fs: sampling frequency (default: 256 Hz)\n",
    "    - nperseg: length of each segment for Welch's method (default: 256)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, subj_data in enumerate(data):\n",
    "        # If subj_data is multi-dimensional, average across the channels\n",
    "        if subj_data.ndim > 1:\n",
    "            subj_data = np.mean(subj_data, axis=0)\n",
    "\n",
    "        f, Pxx = psd(subj_data, fs=fs, nperseg=nperseg)\n",
    "\n",
    "        plt.plot(f, 10 * np.log10(Pxx), label=f'Subject {i+1}')\n",
    "\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power Spectral Density (dB/Hz)')\n",
    "    plt.title('PSD')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "d06431b97537b7c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# barycenter comp functions\n",
    "def compute_normed_barycenter(data):\n",
    "    \"\"\"\n",
    "    Compute the normed barycenter of the given data.\n",
    "\n",
    "    I normalize by each subj's sum, as recommended by Dr. B on slack.\n",
    "\n",
    "    data: list of numpy arrays, each containing EEG data for a subject. Each array has shape (n_channels, n_samples).\n",
    "        Note: these should all be 256 hz, which emotion is natively and cue has been resampled to.\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_psds = []\n",
    "    for subj in data:\n",
    "        f, Pxx = psd(subj)\n",
    "        normalized_psds.append(Pxx / np.sum(Pxx))\n",
    "\n",
    "    # now average all together\n",
    "    barycenter = np.mean(normalized_psds, axis=0)\n",
    "\n",
    "    return barycenter"
   ],
   "id": "ea9b6d3a7cef2fe4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that all data has been loaded and all functions are instantiated, the below code cells calculate and visualize each step.",
   "id": "fed66d518dd8e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# plot the PSD of the emotion data (averaged over channels)",
   "id": "9009f8799cfad096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# plot the normed barycenter of the emotion data\n",
    "emotion_barycenter = compute_normed_barycenter(emotion_data)\n",
    "plt.figure(figsize=(12, 8))\n",
    "#"
   ],
   "id": "6dd271d15a4c9ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# plot the PSD of the frolich data (averaged over channels)",
   "id": "64dde6d804cee60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
